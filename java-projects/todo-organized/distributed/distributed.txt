分布式的主题域
    分布式ID
    分布式Session
    分布式锁
    分布式协作
    分布式缓存
    分布式消息
    分布式服务框架:RPC + 服务治理
    分布式协议
    分布式事务
    分布式计算:flink流式实时计算框架
    分布式内存
    分布式文件系统
    分布式数据库
    分布式系统之负载均衡:HAProxy Nginx; Varnish Squid
    分布式监控系统

相应的开发 运维 管理等工作成本
--------------------------------------------------------------------------------------
DISTRIBUTED SYSTEMS Concepts and Design Fifth Edition
Distributed Systems - Concepts and Design (5th Edition).pdf
--------------------------------------------------------------------------------------
集群管理: Apache Zookeeper、Paxos 算法、Etcd、Raft、Apache Curator
远程调用: NIO、Netty、epoll、Thrift、Protobuf;  IO技术、序列化技术、服务注册发现路由
--------------------------------------------------------------------------------------
协议
    Raft
    Paxos
raft论文:raft.pdf
raft协议   In Search of an Understandable Consensus Algorithm (Extended Version)
------------------------------------------------------------
分布式已有代码
    Dubbo
    Zookeeper
    Eureka
------------------------------------------------------------
## 2019-07-22

分布式系统是同时跨越多个物理主机，独立运行的多个软件组件所组成的系统。

主节点选举、崩溃检测和元数据存储(大多数流行的任务，如选举主节点，跟踪有效的从节点，维 护应用元数据)

ZooKeeper使用共享存储模型来实现应用间 的协作和同步原语。对于共享存储本身，又需要在进程和存储间进行网络通信。

消息延迟	处理器性能	时钟偏移


实现主-从模式的系统，必须解决三个关键问题：<br/>
**主节点崩溃**<br/>
1.新的主要主节点需要能够恢复到旧的主要主节点崩溃时的状态<br/>
2.主节点有效，备份主节点却 认为主节点已经崩溃<br/> 3.网络分区,出现脑裂(系统中两个或者多个部分开始独立工作，导致整体行为不一致性)<br/>

**从节点崩溃**<br/>
1.主节点具有检测从节点的崩溃的能力<br/>
2.从节点也许执行了部分任务，也许全部执行完，但没有报告结果。如果整个运算过程产生了其他 作用，有必要执行某些恢复过程来清除之前的状态

**通信故障**<br/>
1.多个从节点执行相同任务的可能性(比如网络分区导致，重新分配一个任务可能会导致两个从节点执 行相同的任务)<br/>
2.通信故障导致的对锁等同步原语的影响<br/>

首先，客户端可以告诉ZooKeeper某些数据的状态是临时状态 （ephemeral）；其次，同时ZooKeeper需要客户端定时发送是否存活的 通知，如果一个客户端未能及时发送通知，那么所有从属于这个客户端 的临时状态的数据将全部被删除。		通过这两个机制，在崩溃或通信故障 发生时，我们就可以预防客户端独立运行而发生的应用宕机。

如果我们不能控制系统中的消息延迟， 就不能确定一个客户端是崩溃还是运行缓慢，因此，当我们猜测一个客 户端已经崩溃，而实际上我们也需要假设客户端仅仅是执行缓慢，其在后续还可能执行一些其他操作。


<br/><br/>
**分布式协作的难点**<br/>
1.应用启动后，所有不同的进程通过某种方法，需要知道应用的配置信息<br/>
2.配置信息也许发生了变化，所有进 程需要变更配置信息<br/>
3.组成员关系的问题，当负载变化时，我们 希望增加或减少新机器和进程<br/>

在开发分布式应用时，就会遇到真正 困难的问题，就不得不面对故障，如崩溃、通信故障等各种情况。这 些问题会在任何可能的点突然出现，甚至无法列举需要处理的所有的情 况。


FLP定律:证明了在 异步通信的分布式系统中，进程崩溃，所有进程可能无法在这个比特位 的配置上达成一致

CAP定律:一致性 （Consistency）、可用性（Availability）和分区容错性（Partition tolerance），该定律指出，当设计一个分布式系统时，我们希望这三种 属性全部满足，但没有系统可以同时满足这三种属性
ZooKeeper的设计尽可能满足一致性和可用性，当然，在发生网络分区 时ZooKeeper也提供了只读能力。
--------------------------------------------------------------------------------------
分布式系统设计理念:
    对服务器硬件要求很低: 可靠性 性能
    横向可扩展性
    不允许单点失效
    尽可能减少节点间通讯开销
    应用服务最好做成无状态的
--------------------------------------------------------------------------------------
https://www.cnblogs.com/shizhijie/p/8378467.html
https://blog.csdn.net/weixin_42333737/article/details/107211582
--------------------------------------------------------------------------------------
分布式系统在分布式层面的基本问题模型
模型  副本 指标

模型
    节点
    通信
    存储
    异常
        机器宕机
        网络异常
        分布式系统的三态
        存储数据丢失
        无法归类的异常
        异常处理的原则
            在设计、推导、验证分布式系统的协议、流程时，最重要的工作之一就是思考在执行流程的每
            个步骤时一旦发生各种异常的情况下系统的处理方式及造成的影响。

            被大量工程实践所检验过的异常处理黄金原则是：任何在设计阶段考虑到的异常情况一定会在
            系统实际运行中发生，但在系统实际运行遇到的异常却很有可能在设计时未能考虑，所以，除非需
            求指标允许，在系统设计时不能放过任何异常情况。

            工程中常常容易出问题的一种思路是认为某种异常出现的概率非常小以至于可以忽略不计。
            这种思路的错误在于只注意到了单次异常事件发生的概率，而忽略了样本的大小。
            即使单次异常概率非常小，由于系统规模和运行时间的作用，事件样本将是一个非常大的值，从而使得异常事件实际
            发生的概率变大。

副本:在分布式系统中为数据或服务提供的冗余
    副本概念
        数据副本是分布式系统解决数据丢失异常的唯一手段。
        服务副本，指数个节点提供某种相同的服务，这种服务一般并不依赖于节点的本地存储，其所需数据一般来自其他节点。
        副本协议:是贯穿整个分布式系统的理论核心。
    副本一致性
        分布式系统通过副本控制协议，使得从系统外部读取系统内部各个副本的数据在一定的约束条件下相同，称之为副本一致性(consistency)。
        副本一致性是针对分布式系统而言的，不是针对某一个副本而言。
        一致性的强弱即约束条件的不同苛刻程度，副本一致性分为若干变种或者级别
            强一致性(strong consistency)：
                任何时刻任何用户或节点都可以读到最近一次成功更新的副本数据。
                强一致性是程度最高的一致性要求，也是实践中最难以实现的一致性。
            单调一致性(monotonic consistency)：
                任何时刻，任何用户一旦读到某个数据在某次更新后的值，这个用户不会再读到比这个值更旧的值。
                单调一致性是弱于强一致性却非常实用的一种一致性级别。
                因为通常来说，用户只关心从己方视角观察到的一致性，而不会关注其他用户的一致性情况。
            会话一致性(session consistency)：
                任何用户在某一次会话内一旦读到某个数据在某次更新后的值，这个用户在这次会话过程中不会再读到比这个值更旧的值。
                会话一致性只保证单个用户单次会话内数据的单调修改，对于不同用户间的一致性和同一用户不同会话间的一致性没有保障。
            最终一致性(eventual consistency)：
                最终一致性要求一旦更新成功，各个副本上的数据最终将达到完全一致的状态，但达到完全一致状态所需要的时间不能保障。
                对于最终一致性系统而言，一个用户只要始终读取某一个副本的数据，则可以实现类似单调一致性的效果，但一旦用户更换读取的副本，则无法保障任何一致性。
            弱一致性(week consistency)：
                一旦某个更新成功，用户无法在一个确定时间内读到这次更新的值，且即使在某个副本上读到了新的值，也不能保证在其他副本上可以读到新的值。
衡量分布式系统的指标
    性能(performance) 常见的性能指标有：
        系统的吞吐能力:指系统在某一时间可以处理的数据总量，通常可以用系统每秒处理的总的数据量来衡量；
        系统的响应延迟:指系统完成某一功能需要使用的时间
        系统的并发能力，指系统可以同时完成某一功能的能力，通常也用 QPS(query per second)来衡量。
        上述三个性能指标往往会相互制约，追求高吞吐的系统，往往很难做到低延迟；系统平均响应时间较长时，也很难提高QPS。
    可用性(availability):指系统在面对各种异常时可以正确提供服务的能力。
        系统的可用性可以用系统停服务的时间与正常服务的时间的比例来衡量，
        也可以用某功能的失败次数与成功次数的比例来衡量。
        可用性是分布式的重要指标，衡量了系统的鲁棒性，是系统容错能力的体现。
    可扩展性(scalability):分布式系统通过扩展集群机器规模提高系统性能（吞吐、延迟、并发）、存储容量、计算能力的特性。
        分布式系统的设计初衷就是利用集群多机的能力处理单机无法解决的问题。
        完成某一具体任务的所需要的机器数目即集群规模取决于系统的性能和任务的要求。
        当任务的需求随着具体业务不断提高时，除了升级系统的性能，另一个做法就是通过增加机器的方式扩展系统的规模。
        好的分布式系统总在追求“线性扩展性”，也就是使得系统的某一指标可以随着集群中的机器数量线性增长。
    一致性:为了提高可用性，总是不可避免的使用副本的机制，从而引发副本一致性的问题。
        根据具体的业务需求的不同，分布式系统总是提供某种一致性模型，并基于此模型提供具体的服务。
        越是强的一致的性模型，对于用户使用来说使用起来越简单。


分布式系统原理
    数据分布方式 基本副本协议

数据分布方式
    单机系统与分布式系统的最大的区别在于问题的规模，即计算、存储的数据量的区别。
    无论是计算还是存储，其问题输入对象都是数据，所以如何拆解分布式系统的输入数据成为分布式系统的基本问题
    几种常见的数据分布方式：哈希方式

哈希方式(数据分布方式)
    其方法是按照数据的某一特征计算哈希值，并将哈希值与机器中的机器建立映射关系，从而将不同哈希值的数据分布到不同的机器上。
        所谓数据特征可以是key-value 系统中的 key，也可以是其他与应用业务逻辑相关的值。
        只要哈希函数的散列特性较好，哈希方式可以较为均匀的将数据分布到集群中去。
        哈希方式需要记录的元信息也非常简单，任何时候，任何节点只需要知道哈希函数的计算方式及模的服务器总数就可以计算出处理具体数据的机器是哪台。
    哈希分布数据的缺点同样明显，突出表现为可扩展性不高，一旦集群规模需要扩展，则几乎所有的数据需要被迁移并重新分布。
        工程中，扩展哈希分布数据的系统时，往往使得集群规模成倍扩展，按照数据重新计算哈希，这样原本一台机器上的数据只需迁移一半到另一台对应的机器上即可完成扩展。
        针对哈希方式扩展性差的问题，一种思路是不再简单的将哈希值与机器做除法取模映射，而是将对应关系作为元数据由专门的元数据服务器管理。
    哈希分布数据的另一个缺点是，一旦某数据特征值的数据严重不均，容易出现“数据倾斜”（data skew）问题。

按数据范围分布(数据分布方式):
    按数据范围分布是另一个常见的数据分布式，将数据按特征值的值域范围划分为不同的区间，使得集群中每台（组）服务器处理不同区间的数据。
        工程中，为了数据迁移等负载均衡操作的方便，往往利用动态划分区间的技术，使得每个区间中服务的数据量尽量的一样多。
        当某个区间的数据量较大时，通过将区间“分裂”的方式拆分为两个区间，使得每个数据区间中的数据量都尽量维持在一个较为固定的阈值之下。
        实际工程中，一般也不按照某一维度划分数据范围，而是使用全部数据划分范围，从而避免数据倾斜的问题。
    按数据范围分布数据需要记录所有的数据分布情况。
        一般的，往往需要使用专门的服务器在内存中维护数据分布信息，称这种数据的分布信息为一种元信息。
        对于大规模的集群，由于元信息的规模非常庞大，单台计算机无法独立维护，需要使用多台机器作为元信息服务器。
        按范围分数据的方式则使得从全局看数据类似一个 B 树。每个具体的服务器都是 B 树的叶子节点，元数据服务器是 B 树的中间节点。
    优点:
        使用范围分布数据的方式的最大优点就是可以灵活的根据数据量的具体情况拆分原有数据区间，拆分后的数据区间可以迁移到其他机器，一旦需要集群完成负载均衡时，与哈希方式相比非常灵活。
        当集群需要扩容时，可以随意添加机器，而不限为倍增的方式，只需将原机器上的部分数据分区迁移到新加入的机器上就可以完成集群扩容。
    缺点
        是需要维护较为复杂的元信息。随着集群规模的增长，元数据服务器较为容易成为瓶颈，从而需要较为负责的多元数据服务器机制解决这个问题。

数据量分布数据(数据分布方式):
    数据量分布数据与具体的数据特征无关，而是将数据视为一个顺序增长的文件，并将这个文件按照某一较为固定的大小划分为若干数据块（chunk），不同的数据块分布到不同的服务器上。
    与按数据范围分布数据的方式类似的是，按数据量分布数据也需要记录数据块的具体分布情况，并将该分布信息作为元数据使用元数据服务器管理。
    优点:
        由于与具体的数据内容无关，数据总是被均匀切分并分布到集群中。
        当集群需要重新负载均衡时，只需通过迁移数据块即可完成。
        集群扩容也没有太大的限制，只需将部分数据库迁移到新加入的机器上即可以完成扩容。
    缺点
        是需要管理较为复杂的元信息，与按范围分布数据的方式类似，当集群规模较大时，元信息的数据量也变得很大，高效的管理元信息成为新的课题。


一致性哈希（consistent hashing）
    基本方式是使用一个哈希函数计算数据或数据特征的哈希值，令该哈希函数的输出值域为一个封闭的环，即哈希函数输出的最大值是最小值的前序。
    将节点随机分布到这个环上，每个节点负责处理从自己开始顺时针至下一个节点的全部哈希值域上的数据。
    使用一致性哈希的方式需要将节点在一致性哈希环上的位置作为元信息加以管理，这点比直接使用哈希分布数据的方式要复杂。
        节点的位置信息只于集群中的机器规模相关，其元信息的量通常比按数据范围分布数据和按数据量分布数据的元信息量要小很多。
    优点:
        在于可以任意动态添加、删除节点，每次添加、删除一个节点仅影响一致性哈希环上相邻的节点。
    缺点:
        在集群扩容时非常复杂，往往需要倍增节点个数
        随机分布节点的方式使得很难均匀的分布哈希值域，尤其在动态增加节点后，即使原先的分布均匀也很难保证继续均匀，
        由此带来的另一个较为严重的缺点是，当一个节点异常时，该节点的压力全部转移到相邻的一个节点，当加入一个新节点时只能为一个相邻节点分摊压力。
        改进：引入虚节点（virtual node）

副本与数据分布
    分布式系统容错、提高可用性的基本手段就是使用副本。对于数据副本的分布方式主要影响系统的可扩展性。
    种基本的数据副本策略是以机器为单位，若干机器互为副本，副本机器之间的数据完全相同。
    更合适的做法不是以机器作为副本单位，而是将数据拆为较合理的数据段，以数据段为单位作为副本。

    工程中，完全按照数据段建立副本会引起需要管理的元数据的开销增大，副本维护的难度也相应增大。
    一种折中的做法是将某些数据段组成一个数据段分组，按数据段分组为粒度进行副本管理。这样做可以将副本粒度控制在一个较为合适的范围内。

--------------------------------------------------------------------------------------
